{"cells":[{"cell_type":"markdown","metadata":{"id":"ZguKQsaEtw45"},"source":["# Assignment 1"]},{"cell_type":"markdown","metadata":{"id":"RxvUeukG506E"},"source":["#### Student ID: M124111043\n","\n","#### Name: 唐嘉宏"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"gI6a-hc4VIc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n","Note: you may need to restart the kernel to use updated packages.\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install --pre pycaret[full] -qq\n","%pip install cleanlab -qq\n","%pip install snorkel -qq\n"]},{"cell_type":"markdown","metadata":{"id":"aBDkj0NJ18kk"},"source":["## Q1: Exploring a Low-Code ML Framework with Melbourne Housing dataset"]},{"cell_type":"markdown","metadata":{"id":"fCntJOu5qJkQ"},"source":["After completing the California census data project, we will shift our focus to a different housing dataset.\n","\n","The dataset is a snapshot of a [dataset](https://www.kaggle.com/datasets/anthonypino/melbourne-housing-market) created by Tony Pino. This dataset is a compilation of housing market data for Melbourne, which was sourced from weekly public listings on [Domain.com.au](https://www.domain.com.au/). It includes various details such as the address, type of real estate, suburb, selling method, number of rooms, price, real estate agent, date of sale, and the distance from the central business district, among others. **Ensure to set the random seed to 2024 for reproducibility.**\n","\n","To begin, execute the following code snippet for data preparation:\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"CuXdXPyheslS"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Suburb</th>\n","      <th>Rooms</th>\n","      <th>Type</th>\n","      <th>Price</th>\n","      <th>Method</th>\n","      <th>SellerG</th>\n","      <th>Distance</th>\n","      <th>Postcode</th>\n","      <th>Bedroom2</th>\n","      <th>Bathroom</th>\n","      <th>Car</th>\n","      <th>Landsize</th>\n","      <th>BuildingArea</th>\n","      <th>YearBuilt</th>\n","      <th>CouncilArea</th>\n","      <th>Lattitude</th>\n","      <th>Longtitude</th>\n","      <th>Regionname</th>\n","      <th>Propertycount</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Abbotsford</td>\n","      <td>2</td>\n","      <td>h</td>\n","      <td>1480000.0</td>\n","      <td>S</td>\n","      <td>Biggin</td>\n","      <td>2.5</td>\n","      <td>3067.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>202.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Yarra</td>\n","      <td>-37.79960</td>\n","      <td>144.99840</td>\n","      <td>Northern Metropolitan</td>\n","      <td>4019.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Abbotsford</td>\n","      <td>2</td>\n","      <td>h</td>\n","      <td>1035000.0</td>\n","      <td>S</td>\n","      <td>Biggin</td>\n","      <td>2.5</td>\n","      <td>3067.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>156.0</td>\n","      <td>79.0</td>\n","      <td>1900.0</td>\n","      <td>Yarra</td>\n","      <td>-37.80790</td>\n","      <td>144.99340</td>\n","      <td>Northern Metropolitan</td>\n","      <td>4019.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Abbotsford</td>\n","      <td>3</td>\n","      <td>h</td>\n","      <td>1465000.0</td>\n","      <td>SP</td>\n","      <td>Biggin</td>\n","      <td>2.5</td>\n","      <td>3067.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>134.0</td>\n","      <td>150.0</td>\n","      <td>1900.0</td>\n","      <td>Yarra</td>\n","      <td>-37.80930</td>\n","      <td>144.99440</td>\n","      <td>Northern Metropolitan</td>\n","      <td>4019.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Abbotsford</td>\n","      <td>3</td>\n","      <td>h</td>\n","      <td>850000.0</td>\n","      <td>PI</td>\n","      <td>Biggin</td>\n","      <td>2.5</td>\n","      <td>3067.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>94.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Yarra</td>\n","      <td>-37.79690</td>\n","      <td>144.99690</td>\n","      <td>Northern Metropolitan</td>\n","      <td>4019.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Abbotsford</td>\n","      <td>4</td>\n","      <td>h</td>\n","      <td>1600000.0</td>\n","      <td>VB</td>\n","      <td>Nelson</td>\n","      <td>2.5</td>\n","      <td>3067.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>120.0</td>\n","      <td>142.0</td>\n","      <td>2014.0</td>\n","      <td>Yarra</td>\n","      <td>-37.80720</td>\n","      <td>144.99410</td>\n","      <td>Northern Metropolitan</td>\n","      <td>4019.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13575</th>\n","      <td>Wheelers Hill</td>\n","      <td>4</td>\n","      <td>h</td>\n","      <td>1245000.0</td>\n","      <td>S</td>\n","      <td>Barry</td>\n","      <td>16.7</td>\n","      <td>3150.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>652.0</td>\n","      <td>NaN</td>\n","      <td>1981.0</td>\n","      <td>NaN</td>\n","      <td>-37.90562</td>\n","      <td>145.16761</td>\n","      <td>South-Eastern Metropolitan</td>\n","      <td>7392.0</td>\n","    </tr>\n","    <tr>\n","      <th>13576</th>\n","      <td>Williamstown</td>\n","      <td>3</td>\n","      <td>h</td>\n","      <td>1031000.0</td>\n","      <td>SP</td>\n","      <td>Williams</td>\n","      <td>6.8</td>\n","      <td>3016.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>333.0</td>\n","      <td>133.0</td>\n","      <td>1995.0</td>\n","      <td>NaN</td>\n","      <td>-37.85927</td>\n","      <td>144.87904</td>\n","      <td>Western Metropolitan</td>\n","      <td>6380.0</td>\n","    </tr>\n","    <tr>\n","      <th>13577</th>\n","      <td>Williamstown</td>\n","      <td>3</td>\n","      <td>h</td>\n","      <td>1170000.0</td>\n","      <td>S</td>\n","      <td>Raine</td>\n","      <td>6.8</td>\n","      <td>3016.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>436.0</td>\n","      <td>NaN</td>\n","      <td>1997.0</td>\n","      <td>NaN</td>\n","      <td>-37.85274</td>\n","      <td>144.88738</td>\n","      <td>Western Metropolitan</td>\n","      <td>6380.0</td>\n","    </tr>\n","    <tr>\n","      <th>13578</th>\n","      <td>Williamstown</td>\n","      <td>4</td>\n","      <td>h</td>\n","      <td>2500000.0</td>\n","      <td>PI</td>\n","      <td>Sweeney</td>\n","      <td>6.8</td>\n","      <td>3016.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>866.0</td>\n","      <td>157.0</td>\n","      <td>1920.0</td>\n","      <td>NaN</td>\n","      <td>-37.85908</td>\n","      <td>144.89299</td>\n","      <td>Western Metropolitan</td>\n","      <td>6380.0</td>\n","    </tr>\n","    <tr>\n","      <th>13579</th>\n","      <td>Yarraville</td>\n","      <td>4</td>\n","      <td>h</td>\n","      <td>1285000.0</td>\n","      <td>SP</td>\n","      <td>Village</td>\n","      <td>6.3</td>\n","      <td>3013.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>362.0</td>\n","      <td>112.0</td>\n","      <td>1920.0</td>\n","      <td>NaN</td>\n","      <td>-37.81188</td>\n","      <td>144.88449</td>\n","      <td>Western Metropolitan</td>\n","      <td>6543.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13580 rows × 19 columns</p>\n","</div>"],"text/plain":["              Suburb  Rooms Type      Price Method   SellerG  Distance  \\\n","0         Abbotsford      2    h  1480000.0      S    Biggin       2.5   \n","1         Abbotsford      2    h  1035000.0      S    Biggin       2.5   \n","2         Abbotsford      3    h  1465000.0     SP    Biggin       2.5   \n","3         Abbotsford      3    h   850000.0     PI    Biggin       2.5   \n","4         Abbotsford      4    h  1600000.0     VB    Nelson       2.5   \n","...              ...    ...  ...        ...    ...       ...       ...   \n","13575  Wheelers Hill      4    h  1245000.0      S     Barry      16.7   \n","13576   Williamstown      3    h  1031000.0     SP  Williams       6.8   \n","13577   Williamstown      3    h  1170000.0      S     Raine       6.8   \n","13578   Williamstown      4    h  2500000.0     PI   Sweeney       6.8   \n","13579     Yarraville      4    h  1285000.0     SP   Village       6.3   \n","\n","       Postcode  Bedroom2  Bathroom  Car  Landsize  BuildingArea  YearBuilt  \\\n","0        3067.0       2.0       1.0  1.0     202.0           NaN        NaN   \n","1        3067.0       2.0       1.0  0.0     156.0          79.0     1900.0   \n","2        3067.0       3.0       2.0  0.0     134.0         150.0     1900.0   \n","3        3067.0       3.0       2.0  1.0      94.0           NaN        NaN   \n","4        3067.0       3.0       1.0  2.0     120.0         142.0     2014.0   \n","...         ...       ...       ...  ...       ...           ...        ...   \n","13575    3150.0       4.0       2.0  2.0     652.0           NaN     1981.0   \n","13576    3016.0       3.0       2.0  2.0     333.0         133.0     1995.0   \n","13577    3016.0       3.0       2.0  4.0     436.0           NaN     1997.0   \n","13578    3016.0       4.0       1.0  5.0     866.0         157.0     1920.0   \n","13579    3013.0       4.0       1.0  1.0     362.0         112.0     1920.0   \n","\n","      CouncilArea  Lattitude  Longtitude                  Regionname  \\\n","0           Yarra  -37.79960   144.99840       Northern Metropolitan   \n","1           Yarra  -37.80790   144.99340       Northern Metropolitan   \n","2           Yarra  -37.80930   144.99440       Northern Metropolitan   \n","3           Yarra  -37.79690   144.99690       Northern Metropolitan   \n","4           Yarra  -37.80720   144.99410       Northern Metropolitan   \n","...           ...        ...         ...                         ...   \n","13575         NaN  -37.90562   145.16761  South-Eastern Metropolitan   \n","13576         NaN  -37.85927   144.87904        Western Metropolitan   \n","13577         NaN  -37.85274   144.88738        Western Metropolitan   \n","13578         NaN  -37.85908   144.89299        Western Metropolitan   \n","13579         NaN  -37.81188   144.88449        Western Metropolitan   \n","\n","       Propertycount  \n","0             4019.0  \n","1             4019.0  \n","2             4019.0  \n","3             4019.0  \n","4             4019.0  \n","...              ...  \n","13575         7392.0  \n","13576         6380.0  \n","13577         6380.0  \n","13578         6380.0  \n","13579         6543.0  \n","\n","[13580 rows x 19 columns]"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import pandas as pd\n","from pycaret.regression import *\n","\n","# Prepare data\n","df = pd.read_csv(\"melb_data.csv\")\n","df = df.drop(['Date', 'Address'], axis=1)\n","df = df.copy()\n","df"]},{"cell_type":"markdown","metadata":{"id":"k3Ff3rtBnklY"},"source":["**(a) Data Splitting**: Using the `train_test_split()` function, divide the dataset into two parts: a training set and a test set. Allocate 5% of the data to the test set, which will be used for testing purposes. (5%)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"rsuScsCin-oE"},"outputs":[{"name":"stdout","output_type":"stream","text":["training set: 12901\n","testing set: 679\n"]}],"source":["# coding your answer here.\n","from sklearn.model_selection import train_test_split\n","\n","X = df.drop('Price', axis=1)\n","y = df['Price']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=2024)\n","\n","print(f\"training set: {len(X_train)}\")\n","print(f\"testing set: {len(X_test)}\")"]},{"cell_type":"markdown","metadata":{"id":"XvzpnzpQqqlx"},"source":["**(b) Dataset Preparation Using PyCaret:**\n","Prepare the dataset for our machine learning model using the `setup()` function from `PyCaret` with the following requirements: (10%)\n","\n","- **Features**: Include all features in the `df` dataframe, except for the `Price` column, which will be used as the target.\n","- **Target**: Set `Price` as the target variable.\n","- **Validation Set**: Split 20% of the data into a validation set to evaluate the model.\n","- **Missing Values**:\n","  - For numerical variables, replace missing values with the median value of the respective columns. Assume that columns of data type `object` are categorical variables, and all others are numerical.\n","  - For categorical variables, replace missing values with the most frequent value in each column.\n","- **Encoding**:\n","  - Apply one-hot encoding to categorical variables that have fewer than 10 categories.\n","  - Use target encoding for categorical columns with 10 or more categories.\n","- **Standardization**: All features should be standardized. Note that PyCaret automatically scales all features by default.\n","\n","**Hint:** Refer to the PyCaret documentation [here](https://pycaret.readthedocs.io/en/latest/api/regression.html) for additional details on setup parameters. Be aware of how PyCaret handles feature scaling by default as discussed [here](https://github.com/pycaret/pycaret/issues/3076)."]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/html":["<style type=\"text/css\">\n","#T_935ef_row10_col1, #T_935ef_row16_col1 {\n","  background-color: lightgreen;\n","}\n","</style>\n","<table id=\"T_935ef\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_935ef_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n","      <th id=\"T_935ef_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_935ef_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_935ef_row0_col0\" class=\"data row0 col0\" >Session id</td>\n","      <td id=\"T_935ef_row0_col1\" class=\"data row0 col1\" >2024</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n","      <td id=\"T_935ef_row1_col0\" class=\"data row1 col0\" >Target</td>\n","      <td id=\"T_935ef_row1_col1\" class=\"data row1 col1\" >Price</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n","      <td id=\"T_935ef_row2_col0\" class=\"data row2 col0\" >Target type</td>\n","      <td id=\"T_935ef_row2_col1\" class=\"data row2 col1\" >Regression</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n","      <td id=\"T_935ef_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n","      <td id=\"T_935ef_row3_col1\" class=\"data row3 col1\" >(13580, 21)</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n","      <td id=\"T_935ef_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n","      <td id=\"T_935ef_row4_col1\" class=\"data row4 col1\" >(13580, 34)</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n","      <td id=\"T_935ef_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n","      <td id=\"T_935ef_row5_col1\" class=\"data row5 col1\" >(10864, 34)</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n","      <td id=\"T_935ef_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n","      <td id=\"T_935ef_row6_col1\" class=\"data row6 col1\" >(2716, 34)</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n","      <td id=\"T_935ef_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n","      <td id=\"T_935ef_row7_col1\" class=\"data row7 col1\" >12</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n","      <td id=\"T_935ef_row8_col0\" class=\"data row8 col0\" >Categorical features</td>\n","      <td id=\"T_935ef_row8_col1\" class=\"data row8 col1\" >8</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n","      <td id=\"T_935ef_row9_col0\" class=\"data row9 col0\" >Rows with missing values</td>\n","      <td id=\"T_935ef_row9_col1\" class=\"data row9 col1\" >54.4%</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n","      <td id=\"T_935ef_row10_col0\" class=\"data row10 col0\" >Preprocess</td>\n","      <td id=\"T_935ef_row10_col1\" class=\"data row10 col1\" >True</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n","      <td id=\"T_935ef_row11_col0\" class=\"data row11 col0\" >Imputation type</td>\n","      <td id=\"T_935ef_row11_col1\" class=\"data row11 col1\" >simple</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n","      <td id=\"T_935ef_row12_col0\" class=\"data row12 col0\" >Numeric imputation</td>\n","      <td id=\"T_935ef_row12_col1\" class=\"data row12 col1\" >median</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n","      <td id=\"T_935ef_row13_col0\" class=\"data row13 col0\" >Categorical imputation</td>\n","      <td id=\"T_935ef_row13_col1\" class=\"data row13 col1\" >mode</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n","      <td id=\"T_935ef_row14_col0\" class=\"data row14 col0\" >Maximum one-hot encoding</td>\n","      <td id=\"T_935ef_row14_col1\" class=\"data row14 col1\" >25</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n","      <td id=\"T_935ef_row15_col0\" class=\"data row15 col0\" >Encoding method</td>\n","      <td id=\"T_935ef_row15_col1\" class=\"data row15 col1\" >None</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n","      <td id=\"T_935ef_row16_col0\" class=\"data row16 col0\" >Normalize</td>\n","      <td id=\"T_935ef_row16_col1\" class=\"data row16 col1\" >True</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n","      <td id=\"T_935ef_row17_col0\" class=\"data row17 col0\" >Normalize method</td>\n","      <td id=\"T_935ef_row17_col1\" class=\"data row17 col1\" >zscore</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n","      <td id=\"T_935ef_row18_col0\" class=\"data row18 col0\" >Fold Generator</td>\n","      <td id=\"T_935ef_row18_col1\" class=\"data row18 col1\" >KFold</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n","      <td id=\"T_935ef_row19_col0\" class=\"data row19 col0\" >Fold Number</td>\n","      <td id=\"T_935ef_row19_col1\" class=\"data row19 col1\" >5</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n","      <td id=\"T_935ef_row20_col0\" class=\"data row20 col0\" >CPU Jobs</td>\n","      <td id=\"T_935ef_row20_col1\" class=\"data row20 col1\" >-1</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n","      <td id=\"T_935ef_row21_col0\" class=\"data row21 col0\" >Use GPU</td>\n","      <td id=\"T_935ef_row21_col1\" class=\"data row21 col1\" >False</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n","      <td id=\"T_935ef_row22_col0\" class=\"data row22 col0\" >Log Experiment</td>\n","      <td id=\"T_935ef_row22_col1\" class=\"data row22 col1\" >False</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n","      <td id=\"T_935ef_row23_col0\" class=\"data row23 col0\" >Experiment Name</td>\n","      <td id=\"T_935ef_row23_col1\" class=\"data row23 col1\" >reg-default-name</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_935ef_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n","      <td id=\"T_935ef_row24_col0\" class=\"data row24 col0\" >USI</td>\n","      <td id=\"T_935ef_row24_col1\" class=\"data row24 col1\" >1ef4</td>\n","    </tr>\n","  </tbody>\n","</table>\n"],"text/plain":["<pandas.io.formats.style.Styler at 0x1776f36c070>"]},"metadata":{},"output_type":"display_data"}],"source":["from pycaret.regression import setup\n","\n","regression_setup = setup(\n","    data=df, \n","    target='Price', \n","    train_size=0.8, \n","    numeric_imputation='median', \n","    categorical_imputation='mode', \n","    normalize=True, \n","    normalize_method='zscore', \n","    fold=5,\n","    session_id=2024\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"8fI83nw-5j_i"},"source":["After setting up your dataset with `PyCaret`, you can review the configuration and steps of the created machine learning pipeline by executing the following code snippet. This will help you verify that all preprocessing steps are correctly applied as per the requirements:"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"oNz3shMXfZ9X"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-1 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-1 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-1 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-1 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-1 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-1 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-1 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-1 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-1 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-1 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-1 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-1 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-1 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-1 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-1 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-1 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(memory=FastMemory(location=C:\\Users\\User\\AppData\\Local\\Temp\\joblib),\n","         steps=[(&#x27;numerical_imputer&#x27;,\n","                 TransformerWrapper(include=[&#x27;Rooms&#x27;, &#x27;Distance&#x27;, &#x27;Postcode&#x27;,\n","                                             &#x27;Bedroom2&#x27;, &#x27;Bathroom&#x27;, &#x27;Car&#x27;,\n","                                             &#x27;Landsize&#x27;, &#x27;BuildingArea&#x27;,\n","                                             &#x27;YearBuilt&#x27;, &#x27;Lattitude&#x27;,\n","                                             &#x27;Longtitude&#x27;, &#x27;Propertycount&#x27;],\n","                                    transformer=SimpleImputer(strategy=&#x27;median&#x27;))),\n","                (&#x27;categorical_imputer&#x27;,\n","                 Transform...\n","                                    transformer=OneHotEncoder(cols=[&#x27;Type&#x27;,\n","                                                                    &#x27;Method&#x27;,\n","                                                                    &#x27;Regionname&#x27;],\n","                                                              handle_missing=&#x27;return_nan&#x27;,\n","                                                              use_cat_names=True))),\n","                (&#x27;rest_encoding&#x27;,\n","                 TransformerWrapper(include=[&#x27;Suburb&#x27;, &#x27;Address&#x27;, &#x27;SellerG&#x27;,\n","                                             &#x27;Date&#x27;, &#x27;CouncilArea&#x27;],\n","                                    transformer=TargetEncoder(cols=[&#x27;Suburb&#x27;,\n","                                                                    &#x27;Address&#x27;,\n","                                                                    &#x27;SellerG&#x27;,\n","                                                                    &#x27;Date&#x27;,\n","                                                                    &#x27;CouncilArea&#x27;],\n","                                                              handle_missing=&#x27;return_nan&#x27;))),\n","                (&#x27;normalize&#x27;,\n","                 TransformerWrapper(transformer=StandardScaler()))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Pipeline<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(memory=FastMemory(location=C:\\Users\\User\\AppData\\Local\\Temp\\joblib),\n","         steps=[(&#x27;numerical_imputer&#x27;,\n","                 TransformerWrapper(include=[&#x27;Rooms&#x27;, &#x27;Distance&#x27;, &#x27;Postcode&#x27;,\n","                                             &#x27;Bedroom2&#x27;, &#x27;Bathroom&#x27;, &#x27;Car&#x27;,\n","                                             &#x27;Landsize&#x27;, &#x27;BuildingArea&#x27;,\n","                                             &#x27;YearBuilt&#x27;, &#x27;Lattitude&#x27;,\n","                                             &#x27;Longtitude&#x27;, &#x27;Propertycount&#x27;],\n","                                    transformer=SimpleImputer(strategy=&#x27;median&#x27;))),\n","                (&#x27;categorical_imputer&#x27;,\n","                 Transform...\n","                                    transformer=OneHotEncoder(cols=[&#x27;Type&#x27;,\n","                                                                    &#x27;Method&#x27;,\n","                                                                    &#x27;Regionname&#x27;],\n","                                                              handle_missing=&#x27;return_nan&#x27;,\n","                                                              use_cat_names=True))),\n","                (&#x27;rest_encoding&#x27;,\n","                 TransformerWrapper(include=[&#x27;Suburb&#x27;, &#x27;Address&#x27;, &#x27;SellerG&#x27;,\n","                                             &#x27;Date&#x27;, &#x27;CouncilArea&#x27;],\n","                                    transformer=TargetEncoder(cols=[&#x27;Suburb&#x27;,\n","                                                                    &#x27;Address&#x27;,\n","                                                                    &#x27;SellerG&#x27;,\n","                                                                    &#x27;Date&#x27;,\n","                                                                    &#x27;CouncilArea&#x27;],\n","                                                              handle_missing=&#x27;return_nan&#x27;))),\n","                (&#x27;normalize&#x27;,\n","                 TransformerWrapper(transformer=StandardScaler()))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">numerical_imputer: TransformerWrapper</label><div class=\"sk-toggleable__content fitted\"><pre>TransformerWrapper(include=[&#x27;Rooms&#x27;, &#x27;Distance&#x27;, &#x27;Postcode&#x27;, &#x27;Bedroom2&#x27;,\n","                            &#x27;Bathroom&#x27;, &#x27;Car&#x27;, &#x27;Landsize&#x27;, &#x27;BuildingArea&#x27;,\n","                            &#x27;YearBuilt&#x27;, &#x27;Lattitude&#x27;, &#x27;Longtitude&#x27;,\n","                            &#x27;Propertycount&#x27;],\n","                   transformer=SimpleImputer(strategy=&#x27;median&#x27;))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">transformer: SimpleImputer</label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">categorical_imputer: TransformerWrapper</label><div class=\"sk-toggleable__content fitted\"><pre>TransformerWrapper(include=[&#x27;Suburb&#x27;, &#x27;Address&#x27;, &#x27;Type&#x27;, &#x27;Method&#x27;, &#x27;SellerG&#x27;,\n","                            &#x27;Date&#x27;, &#x27;CouncilArea&#x27;, &#x27;Regionname&#x27;],\n","                   transformer=SimpleImputer(strategy=&#x27;most_frequent&#x27;))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">transformer: SimpleImputer</label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">onehot_encoding: TransformerWrapper</label><div class=\"sk-toggleable__content fitted\"><pre>TransformerWrapper(include=[&#x27;Type&#x27;, &#x27;Method&#x27;, &#x27;Regionname&#x27;],\n","                   transformer=OneHotEncoder(cols=[&#x27;Type&#x27;, &#x27;Method&#x27;,\n","                                                   &#x27;Regionname&#x27;],\n","                                             handle_missing=&#x27;return_nan&#x27;,\n","                                             use_cat_names=True))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">transformer: OneHotEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(cols=[&#x27;Type&#x27;, &#x27;Method&#x27;, &#x27;Regionname&#x27;],\n","              handle_missing=&#x27;return_nan&#x27;, use_cat_names=True)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">OneHotEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(cols=[&#x27;Type&#x27;, &#x27;Method&#x27;, &#x27;Regionname&#x27;],\n","              handle_missing=&#x27;return_nan&#x27;, use_cat_names=True)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">rest_encoding: TransformerWrapper</label><div class=\"sk-toggleable__content fitted\"><pre>TransformerWrapper(include=[&#x27;Suburb&#x27;, &#x27;Address&#x27;, &#x27;SellerG&#x27;, &#x27;Date&#x27;,\n","                            &#x27;CouncilArea&#x27;],\n","                   transformer=TargetEncoder(cols=[&#x27;Suburb&#x27;, &#x27;Address&#x27;,\n","                                                   &#x27;SellerG&#x27;, &#x27;Date&#x27;,\n","                                                   &#x27;CouncilArea&#x27;],\n","                                             handle_missing=&#x27;return_nan&#x27;))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">transformer: TargetEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>TargetEncoder(cols=[&#x27;Suburb&#x27;, &#x27;Address&#x27;, &#x27;SellerG&#x27;, &#x27;Date&#x27;, &#x27;CouncilArea&#x27;],\n","              handle_missing=&#x27;return_nan&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">TargetEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>TargetEncoder(cols=[&#x27;Suburb&#x27;, &#x27;Address&#x27;, &#x27;SellerG&#x27;, &#x27;Date&#x27;, &#x27;CouncilArea&#x27;],\n","              handle_missing=&#x27;return_nan&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">normalize: TransformerWrapper</label><div class=\"sk-toggleable__content fitted\"><pre>TransformerWrapper(transformer=StandardScaler())</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">transformer: StandardScaler</label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"],"text/plain":["Pipeline(memory=FastMemory(location=C:\\Users\\User\\AppData\\Local\\Temp\\joblib),\n","         steps=[('numerical_imputer',\n","                 TransformerWrapper(include=['Rooms', 'Distance', 'Postcode',\n","                                             'Bedroom2', 'Bathroom', 'Car',\n","                                             'Landsize', 'BuildingArea',\n","                                             'YearBuilt', 'Lattitude',\n","                                             'Longtitude', 'Propertycount'],\n","                                    transformer=SimpleImputer(strategy='median'))),\n","                ('categorical_imputer',\n","                 Transform...\n","                                    transformer=OneHotEncoder(cols=['Type',\n","                                                                    'Method',\n","                                                                    'Regionname'],\n","                                                              handle_missing='return_nan',\n","                                                              use_cat_names=True))),\n","                ('rest_encoding',\n","                 TransformerWrapper(include=['Suburb', 'Address', 'SellerG',\n","                                             'Date', 'CouncilArea'],\n","                                    transformer=TargetEncoder(cols=['Suburb',\n","                                                                    'Address',\n","                                                                    'SellerG',\n","                                                                    'Date',\n","                                                                    'CouncilArea'],\n","                                                              handle_missing='return_nan'))),\n","                ('normalize',\n","                 TransformerWrapper(transformer=StandardScaler()))])"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# Get the PyCaret configuration\n","config = get_config('pipeline')\n","config"]},{"cell_type":"markdown","metadata":{"id":"G-Llf3dx-p7e"},"source":["**(c) Verify Transformed Data:**\n","Use the `get_config()` function in `PyCaret` to inspect the transformed dataset. After executing this function, review the output to ensure the number of samples and the number of features match your expectations based on the data preparation steps previously outlined. (10%)\n","\n","Provide a brief explanation of why the numbers match or differ from your expectations."]},{"cell_type":"code","execution_count":34,"metadata":{"id":"O1H0FVaIbX-q"},"outputs":[{"name":"stdout","output_type":"stream","text":["Transformed Features Shape: (13580, 20)\n","Transformed Target Shape: (13580,)\n"]}],"source":["# coding your answer here.\n","from pycaret.regression import get_config\n","\n","X_transformed = get_config('X')  \n","y_transformed = get_config('y')  \n","\n","print(f\"Transformed Features Shape: {X_transformed.shape}\")\n","print(f\"Transformed Target Shape: {y_transformed.shape}\")\n"]},{"cell_type":"markdown","metadata":{"id":"U2NamG2QD05O"},"source":["> Ans: *double click here to answer the question.* <bd>\n","\n","Column沒有符合預期，應該會是34而不是20, 因為One-hot增加少量列別，但Target壓縮多個類別。\n","而Row是符合預期的，因為對於缺失值是進行補值處理而非直接刪除。"]},{"cell_type":"markdown","metadata":{"id":"8fSsEjKA88Jc"},"source":["**(d) Model Comparison and Evaluation:** (5%)\n","\n","Utilize the `compare_models()` function in `PyCaret` to conduct a 3-fold cross-validation analysis. Compare the performance of the following machine learning models:\n","\n","- Linear Regression\n","- Lasso Regression\n","- Ridge Regression\n","- Support Vector Regression (SVR)\n","- K-Nearest Neighbor (KNN) Regressor\n","- Random Forest Regressor\n","- XGBoost\n","- LightGBM\n","- CatBoost\n","\n","List the top five models according to their performance on the Mean Absolute Percentage Error (MAPE) measure."]},{"cell_type":"code","execution_count":37,"metadata":{"id":"teo2hgUzBqnH"},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style type=\"text/css\">\n","#T_0b88a th {\n","  text-align: left;\n","}\n","#T_0b88a_row0_col0, #T_0b88a_row1_col0, #T_0b88a_row1_col1, #T_0b88a_row1_col2, #T_0b88a_row1_col3, #T_0b88a_row1_col4, #T_0b88a_row1_col5, #T_0b88a_row1_col6, #T_0b88a_row2_col0, #T_0b88a_row2_col1, #T_0b88a_row2_col2, #T_0b88a_row2_col3, #T_0b88a_row2_col4, #T_0b88a_row2_col5, #T_0b88a_row2_col6, #T_0b88a_row3_col0, #T_0b88a_row3_col1, #T_0b88a_row3_col2, #T_0b88a_row3_col3, #T_0b88a_row3_col4, #T_0b88a_row3_col5, #T_0b88a_row3_col6, #T_0b88a_row4_col0, #T_0b88a_row4_col1, #T_0b88a_row4_col2, #T_0b88a_row4_col3, #T_0b88a_row4_col4, #T_0b88a_row4_col5, #T_0b88a_row4_col6, #T_0b88a_row5_col0, #T_0b88a_row5_col1, #T_0b88a_row5_col2, #T_0b88a_row5_col3, #T_0b88a_row5_col4, #T_0b88a_row5_col5, #T_0b88a_row5_col6, #T_0b88a_row6_col0, #T_0b88a_row6_col1, #T_0b88a_row6_col2, #T_0b88a_row6_col3, #T_0b88a_row6_col4, #T_0b88a_row6_col5, #T_0b88a_row6_col6, #T_0b88a_row7_col0, #T_0b88a_row7_col1, #T_0b88a_row7_col2, #T_0b88a_row7_col3, #T_0b88a_row7_col4, #T_0b88a_row7_col5, #T_0b88a_row7_col6, #T_0b88a_row8_col0, #T_0b88a_row8_col1, #T_0b88a_row8_col2, #T_0b88a_row8_col3, #T_0b88a_row8_col4, #T_0b88a_row8_col5, #T_0b88a_row8_col6 {\n","  text-align: left;\n","}\n","#T_0b88a_row0_col1, #T_0b88a_row0_col2, #T_0b88a_row0_col3, #T_0b88a_row0_col4, #T_0b88a_row0_col5, #T_0b88a_row0_col6 {\n","  text-align: left;\n","  background-color: yellow;\n","}\n","#T_0b88a_row0_col7, #T_0b88a_row1_col7, #T_0b88a_row2_col7, #T_0b88a_row3_col7, #T_0b88a_row4_col7, #T_0b88a_row6_col7, #T_0b88a_row7_col7, #T_0b88a_row8_col7 {\n","  text-align: left;\n","  background-color: lightgrey;\n","}\n","#T_0b88a_row5_col7 {\n","  text-align: left;\n","  background-color: yellow;\n","  background-color: lightgrey;\n","}\n","</style>\n","<table id=\"T_0b88a\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_0b88a_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n","      <th id=\"T_0b88a_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n","      <th id=\"T_0b88a_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n","      <th id=\"T_0b88a_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n","      <th id=\"T_0b88a_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n","      <th id=\"T_0b88a_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n","      <th id=\"T_0b88a_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n","      <th id=\"T_0b88a_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_0b88a_level0_row0\" class=\"row_heading level0 row0\" >knn</th>\n","      <td id=\"T_0b88a_row0_col0\" class=\"data row0 col0\" >K Neighbors Regressor</td>\n","      <td id=\"T_0b88a_row0_col1\" class=\"data row0 col1\" >241780.1719</td>\n","      <td id=\"T_0b88a_row0_col2\" class=\"data row0 col2\" >177782925994.6666</td>\n","      <td id=\"T_0b88a_row0_col3\" class=\"data row0 col3\" >421262.5312</td>\n","      <td id=\"T_0b88a_row0_col4\" class=\"data row0 col4\" >0.5624</td>\n","      <td id=\"T_0b88a_row0_col5\" class=\"data row0 col5\" >0.2817</td>\n","      <td id=\"T_0b88a_row0_col6\" class=\"data row0 col6\" >0.2135</td>\n","      <td id=\"T_0b88a_row0_col7\" class=\"data row0 col7\" >0.1333</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_0b88a_level0_row1\" class=\"row_heading level0 row1\" >svm</th>\n","      <td id=\"T_0b88a_row1_col0\" class=\"data row1 col0\" >Support Vector Regression</td>\n","      <td id=\"T_0b88a_row1_col1\" class=\"data row1 col1\" >439888.9027</td>\n","      <td id=\"T_0b88a_row1_col2\" class=\"data row1 col2\" >434664069814.0724</td>\n","      <td id=\"T_0b88a_row1_col3\" class=\"data row1 col3\" >659170.1475</td>\n","      <td id=\"T_0b88a_row1_col4\" class=\"data row1 col4\" >-0.0715</td>\n","      <td id=\"T_0b88a_row1_col5\" class=\"data row1 col5\" >0.5281</td>\n","      <td id=\"T_0b88a_row1_col6\" class=\"data row1 col6\" >0.4413</td>\n","      <td id=\"T_0b88a_row1_col7\" class=\"data row1 col7\" >1.5000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_0b88a_level0_row2\" class=\"row_heading level0 row2\" >lightgbm</th>\n","      <td id=\"T_0b88a_row2_col0\" class=\"data row2 col0\" >Light Gradient Boosting Machine</td>\n","      <td id=\"T_0b88a_row2_col1\" class=\"data row2 col1\" >452351.2961</td>\n","      <td id=\"T_0b88a_row2_col2\" class=\"data row2 col2\" >393559400100.3706</td>\n","      <td id=\"T_0b88a_row2_col3\" class=\"data row2 col3\" >627255.8798</td>\n","      <td id=\"T_0b88a_row2_col4\" class=\"data row2 col4\" >0.0296</td>\n","      <td id=\"T_0b88a_row2_col5\" class=\"data row2 col5\" >0.5363</td>\n","      <td id=\"T_0b88a_row2_col6\" class=\"data row2 col6\" >0.5340</td>\n","      <td id=\"T_0b88a_row2_col7\" class=\"data row2 col7\" >0.2133</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_0b88a_level0_row3\" class=\"row_heading level0 row3\" >xgboost</th>\n","      <td id=\"T_0b88a_row3_col0\" class=\"data row3 col0\" >Extreme Gradient Boosting</td>\n","      <td id=\"T_0b88a_row3_col1\" class=\"data row3 col1\" >452697.9062</td>\n","      <td id=\"T_0b88a_row3_col2\" class=\"data row3 col2\" >392450845354.6667</td>\n","      <td id=\"T_0b88a_row3_col3\" class=\"data row3 col3\" >626416.2708</td>\n","      <td id=\"T_0b88a_row3_col4\" class=\"data row3 col4\" >0.0319</td>\n","      <td id=\"T_0b88a_row3_col5\" class=\"data row3 col5\" >0.5364</td>\n","      <td id=\"T_0b88a_row3_col6\" class=\"data row3 col6\" >0.5350</td>\n","      <td id=\"T_0b88a_row3_col7\" class=\"data row3 col7\" >0.2300</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_0b88a_level0_row4\" class=\"row_heading level0 row4\" >catboost</th>\n","      <td id=\"T_0b88a_row4_col0\" class=\"data row4 col0\" >CatBoost Regressor</td>\n","      <td id=\"T_0b88a_row4_col1\" class=\"data row4 col1\" >452847.6867</td>\n","      <td id=\"T_0b88a_row4_col2\" class=\"data row4 col2\" >393778638276.8960</td>\n","      <td id=\"T_0b88a_row4_col3\" class=\"data row4 col3\" >627408.6826</td>\n","      <td id=\"T_0b88a_row4_col4\" class=\"data row4 col4\" >0.0293</td>\n","      <td id=\"T_0b88a_row4_col5\" class=\"data row4 col5\" >0.5369</td>\n","      <td id=\"T_0b88a_row4_col6\" class=\"data row4 col6\" >0.5352</td>\n","      <td id=\"T_0b88a_row4_col7\" class=\"data row4 col7\" >1.4467</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_0b88a_level0_row5\" class=\"row_heading level0 row5\" >ridge</th>\n","      <td id=\"T_0b88a_row5_col0\" class=\"data row5 col0\" >Ridge Regression</td>\n","      <td id=\"T_0b88a_row5_col1\" class=\"data row5 col1\" >457943.1405</td>\n","      <td id=\"T_0b88a_row5_col2\" class=\"data row5 col2\" >401123234022.8182</td>\n","      <td id=\"T_0b88a_row5_col3\" class=\"data row5 col3\" >633193.9157</td>\n","      <td id=\"T_0b88a_row5_col4\" class=\"data row5 col4\" >0.0114</td>\n","      <td id=\"T_0b88a_row5_col5\" class=\"data row5 col5\" >0.5422</td>\n","      <td id=\"T_0b88a_row5_col6\" class=\"data row5 col6\" >0.5420</td>\n","      <td id=\"T_0b88a_row5_col7\" class=\"data row5 col7\" >0.0733</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_0b88a_level0_row6\" class=\"row_heading level0 row6\" >lasso</th>\n","      <td id=\"T_0b88a_row6_col0\" class=\"data row6 col0\" >Lasso Regression</td>\n","      <td id=\"T_0b88a_row6_col1\" class=\"data row6 col1\" >458094.1555</td>\n","      <td id=\"T_0b88a_row6_col2\" class=\"data row6 col2\" >401348427595.0462</td>\n","      <td id=\"T_0b88a_row6_col3\" class=\"data row6 col3\" >633371.6242</td>\n","      <td id=\"T_0b88a_row6_col4\" class=\"data row6 col4\" >0.0109</td>\n","      <td id=\"T_0b88a_row6_col5\" class=\"data row6 col5\" >0.5424</td>\n","      <td id=\"T_0b88a_row6_col6\" class=\"data row6 col6\" >0.5422</td>\n","      <td id=\"T_0b88a_row6_col7\" class=\"data row6 col7\" >0.0767</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_0b88a_level0_row7\" class=\"row_heading level0 row7\" >lr</th>\n","      <td id=\"T_0b88a_row7_col0\" class=\"data row7 col0\" >Linear Regression</td>\n","      <td id=\"T_0b88a_row7_col1\" class=\"data row7 col1\" >458314.6982</td>\n","      <td id=\"T_0b88a_row7_col2\" class=\"data row7 col2\" >401742915191.1018</td>\n","      <td id=\"T_0b88a_row7_col3\" class=\"data row7 col3\" >633675.7188</td>\n","      <td id=\"T_0b88a_row7_col4\" class=\"data row7 col4\" >0.0100</td>\n","      <td id=\"T_0b88a_row7_col5\" class=\"data row7 col5\" >0.5426</td>\n","      <td id=\"T_0b88a_row7_col6\" class=\"data row7 col6\" >0.5424</td>\n","      <td id=\"T_0b88a_row7_col7\" class=\"data row7 col7\" >0.0800</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_0b88a_level0_row8\" class=\"row_heading level0 row8\" >rf</th>\n","      <td id=\"T_0b88a_row8_col0\" class=\"data row8 col0\" >Random Forest Regressor</td>\n","      <td id=\"T_0b88a_row8_col1\" class=\"data row8 col1\" >459630.9261</td>\n","      <td id=\"T_0b88a_row8_col2\" class=\"data row8 col2\" >404695800943.6272</td>\n","      <td id=\"T_0b88a_row8_col3\" class=\"data row8 col3\" >636063.5634</td>\n","      <td id=\"T_0b88a_row8_col4\" class=\"data row8 col4\" >0.0023</td>\n","      <td id=\"T_0b88a_row8_col5\" class=\"data row8 col5\" >0.5442</td>\n","      <td id=\"T_0b88a_row8_col6\" class=\"data row8 col6\" >0.5434</td>\n","      <td id=\"T_0b88a_row8_col7\" class=\"data row8 col7\" >0.8067</td>\n","    </tr>\n","  </tbody>\n","</table>\n"],"text/plain":["<pandas.io.formats.style.Styler at 0x1776f6ee100>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["KNeighborsRegressor(n_jobs=-1)\n"]}],"source":["# coding your answer here.\n","from pycaret.regression import compare_models\n","top_models = compare_models(\n","    include=['lr', 'lasso', 'ridge', 'svm', 'knn', 'rf', 'xgboost', 'lightgbm', 'catboost'], \n","    fold=3, \n","    sort='MAPE'\n",")\n","print(top_models)"]},{"cell_type":"markdown","metadata":{"id":"cio2CzZFEB8u"},"source":["> Ans: *double click here to answer the question.*\n","1. KNN\n","2. SVM\n","3. LightGBM\n","4. XGBOOST\n","5. CATBOOST\n"]},{"cell_type":"markdown","metadata":{"id":"X1TICQ99_TbP"},"source":["**(e) Final Model Selection and Evaluation**: Using the `create_model()` function in `PyCaret`, select the best-performing model from part (d) based on the MAPE metric. Evaluate this model on the test set that was reserved in part (a). Report the MAPE on the test set to assess the model’s performance. (5%)"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"1VOS1NxEnCvA"},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style type=\"text/css\">\n","#T_4072d_row5_col0, #T_4072d_row5_col1, #T_4072d_row5_col2, #T_4072d_row5_col3, #T_4072d_row5_col4, #T_4072d_row5_col5 {\n","  background: yellow;\n","}\n","</style>\n","<table id=\"T_4072d\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_4072d_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n","      <th id=\"T_4072d_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n","      <th id=\"T_4072d_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n","      <th id=\"T_4072d_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n","      <th id=\"T_4072d_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n","      <th id=\"T_4072d_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n","    </tr>\n","    <tr>\n","      <th class=\"index_name level0\" >Fold</th>\n","      <th class=\"blank col0\" >&nbsp;</th>\n","      <th class=\"blank col1\" >&nbsp;</th>\n","      <th class=\"blank col2\" >&nbsp;</th>\n","      <th class=\"blank col3\" >&nbsp;</th>\n","      <th class=\"blank col4\" >&nbsp;</th>\n","      <th class=\"blank col5\" >&nbsp;</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_4072d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_4072d_row0_col0\" class=\"data row0 col0\" >239394.6094</td>\n","      <td id=\"T_4072d_row0_col1\" class=\"data row0 col1\" >192827703296.0000</td>\n","      <td id=\"T_4072d_row0_col2\" class=\"data row0 col2\" >439121.5000</td>\n","      <td id=\"T_4072d_row0_col3\" class=\"data row0 col3\" >0.5384</td>\n","      <td id=\"T_4072d_row0_col4\" class=\"data row0 col4\" >0.2791</td>\n","      <td id=\"T_4072d_row0_col5\" class=\"data row0 col5\" >0.2086</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_4072d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n","      <td id=\"T_4072d_row1_col0\" class=\"data row1 col0\" >248183.3750</td>\n","      <td id=\"T_4072d_row1_col1\" class=\"data row1 col1\" >198395150336.0000</td>\n","      <td id=\"T_4072d_row1_col2\" class=\"data row1 col2\" >445415.7188</td>\n","      <td id=\"T_4072d_row1_col3\" class=\"data row1 col3\" >0.5428</td>\n","      <td id=\"T_4072d_row1_col4\" class=\"data row1 col4\" >0.2841</td>\n","      <td id=\"T_4072d_row1_col5\" class=\"data row1 col5\" >0.2106</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_4072d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n","      <td id=\"T_4072d_row2_col0\" class=\"data row2 col0\" >240322.4375</td>\n","      <td id=\"T_4072d_row2_col1\" class=\"data row2 col1\" >161187004416.0000</td>\n","      <td id=\"T_4072d_row2_col2\" class=\"data row2 col2\" >401481.0000</td>\n","      <td id=\"T_4072d_row2_col3\" class=\"data row2 col3\" >0.5745</td>\n","      <td id=\"T_4072d_row2_col4\" class=\"data row2 col4\" >0.2862</td>\n","      <td id=\"T_4072d_row2_col5\" class=\"data row2 col5\" >0.2192</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_4072d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n","      <td id=\"T_4072d_row3_col0\" class=\"data row3 col0\" >235667.3750</td>\n","      <td id=\"T_4072d_row3_col1\" class=\"data row3 col1\" >145497948160.0000</td>\n","      <td id=\"T_4072d_row3_col2\" class=\"data row3 col2\" >381441.9375</td>\n","      <td id=\"T_4072d_row3_col3\" class=\"data row3 col3\" >0.5905</td>\n","      <td id=\"T_4072d_row3_col4\" class=\"data row3 col4\" >0.2791</td>\n","      <td id=\"T_4072d_row3_col5\" class=\"data row3 col5\" >0.2162</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_4072d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n","      <td id=\"T_4072d_row4_col0\" class=\"data row4 col0\" >240605.7031</td>\n","      <td id=\"T_4072d_row4_col1\" class=\"data row4 col1\" >191070437376.0000</td>\n","      <td id=\"T_4072d_row4_col2\" class=\"data row4 col2\" >437116.0312</td>\n","      <td id=\"T_4072d_row4_col3\" class=\"data row4 col3\" >0.5681</td>\n","      <td id=\"T_4072d_row4_col4\" class=\"data row4 col4\" >0.2733</td>\n","      <td id=\"T_4072d_row4_col5\" class=\"data row4 col5\" >0.2044</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_4072d_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n","      <td id=\"T_4072d_row5_col0\" class=\"data row5 col0\" >240834.7000</td>\n","      <td id=\"T_4072d_row5_col1\" class=\"data row5 col1\" >177795648716.8000</td>\n","      <td id=\"T_4072d_row5_col2\" class=\"data row5 col2\" >420915.2375</td>\n","      <td id=\"T_4072d_row5_col3\" class=\"data row5 col3\" >0.5628</td>\n","      <td id=\"T_4072d_row5_col4\" class=\"data row5 col4\" >0.2804</td>\n","      <td id=\"T_4072d_row5_col5\" class=\"data row5 col5\" >0.2118</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_4072d_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n","      <td id=\"T_4072d_row6_col0\" class=\"data row6 col0\" >4076.5914</td>\n","      <td id=\"T_4072d_row6_col1\" class=\"data row6 col1\" >20714780580.7598</td>\n","      <td id=\"T_4072d_row6_col2\" class=\"data row6 col2\" >25020.1451</td>\n","      <td id=\"T_4072d_row6_col3\" class=\"data row6 col3\" >0.0196</td>\n","      <td id=\"T_4072d_row6_col4\" class=\"data row6 col4\" >0.0045</td>\n","      <td id=\"T_4072d_row6_col5\" class=\"data row6 col5\" >0.0053</td>\n","    </tr>\n","  </tbody>\n","</table>\n"],"text/plain":["<pandas.io.formats.style.Styler at 0x1776bbd1670>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["MAPE on the test set: 0.20626136660575867\n"]}],"source":["from pycaret.regression import create_model, predict_model, get_config\n","from sklearn.metrics import mean_absolute_percentage_error\n","\n","best_model = create_model('knn')\n","\n","X_test = get_config('X_test')  \n","y_test = get_config('y_test') \n","\n","predictions = predict_model(best_model, data=X_test)\n","\n","y_pred = predictions['prediction_label']  \n","\n","\n","mape = mean_absolute_percentage_error(y_test, y_pred)\n","print(f\"MAPE on the test set: {mape}\")\n"]},{"cell_type":"markdown","metadata":{"id":"sKTSX0pmEC-O"},"source":["> Ans: *double click here to answer the question.* <bd>\n","\n","MAPE = 0.2063"]},{"cell_type":"markdown","metadata":{"id":"XHmRCbF1VtRO"},"source":["## Q2: Handling an Unlabeled Dataset in a Startup Environment"]},{"cell_type":"markdown","metadata":{"id":"Tzp0m9WpYTUb"},"source":["In this exercise, you'll hone your data preparation skills, a crucial element in many real-world projects. You are provided with an unlabeled dataset `data.csv`, which consists of two features and encompasses 300 sample points. Each sample point is associated with one of four distinct classes. Additionally, you have `crowdsourcing.csv` containing labels from 50 different workers for these sample points.\n","\n","**While this is a practice project, and you have access to the actual ground truth labels in `labels.csv`, these labels are restricted to measuring the accuracy of your models. Under no circumstances should the ground truth labels be used in other parts of the training process.** Ensure to set the random seed to 2024 for all operations requiring randomness to maintain consistency in your results."]},{"cell_type":"markdown","metadata":{"id":"dRV_HimuEXHl"},"source":["Firstly, read the dataset and divide it into training and testing sets using the following code snippet:"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"_C1GOcN9ze_t"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","X = pd.read_csv('data.csv', names=[0,1])\n","true_labels = np.loadtxt(\"labels.csv\", delimiter=',')\n","multiannotator_labels = pd.read_csv('crowdsourcing.csv')"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"UdnFtkrvdHgb"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, multiannotator_labels, ano_unseen, Y_train, Y_test  = train_test_split(X, multiannotator_labels, true_labels, test_size=0.1, random_state=2024)"]},{"cell_type":"markdown","metadata":{"id":"RSa3-5NDIKmB"},"source":["**(a) Label Aggregation Using Snorkel:** (10%)\n","\n","In this task, we'll explore the use of `Snorkel` to manage and refine crowdsourced labels. Each crowd worker will be treated as an individual labeling function since each one labels different subsets of the dataset and might introduce errors or conflicts.\n","\n","**Steps:**\n","\n","1. **Convert Crowdsourcing Data**: Transform the crowdsourcing data frame into a label matrix where each row corresponds to a sample and each column to a worker's label for that sample. This matrix will be used to train the `Snorkel` model.\n","\n","2. **Train the Label Model**: Use the `Snorkel` `LabelModel` to train on the label matrix you created. Apply the following hyperparameters:\n","   ```python\n","   fit(L_train, n_epochs=500, seed=2024, log_freq=20, l2=0.1, lr=0.001, lr_scheduler=\"linear\", optimizer=\"adam\")\n","   ```\n","\n","3. **Generate Predictions and Evaluate Accuracy**: Once trained, use the `LabelModel` to generate predictions for each training sample. Then, calculate the accuracy of these predictions by comparing them against the ground truth labels from `labels.csv`. Remember, the ground truth is only used for evaluating accuracy, not for training the Label Model.\n","\n","**Hints:**\n","- You can check the Snorkel documentation [here](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.model.label_model.LabelModel.html) for more details on the `LabelModel` parameters and methods."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"H3h1IOR5IU53"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:root:Computing O...\n","INFO:root:Estimating \\mu...\n","  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.167]\n","INFO:root:[20 epochs]: TRAIN:[loss=0.097]\n","INFO:root:[40 epochs]: TRAIN:[loss=0.089]\n","INFO:root:[60 epochs]: TRAIN:[loss=0.089]\n"," 12%|█▏        | 62/500 [00:00<00:00, 604.70epoch/s]INFO:root:[80 epochs]: TRAIN:[loss=0.090]\n","INFO:root:[100 epochs]: TRAIN:[loss=0.091]\n","INFO:root:[120 epochs]: TRAIN:[loss=0.091]\n"," 25%|██▌       | 125/500 [00:00<00:00, 613.96epoch/s]INFO:root:[140 epochs]: TRAIN:[loss=0.091]\n","INFO:root:[160 epochs]: TRAIN:[loss=0.091]\n","INFO:root:[180 epochs]: TRAIN:[loss=0.091]\n"," 37%|███▋      | 187/500 [00:00<00:00, 607.01epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.091]\n","INFO:root:[220 epochs]: TRAIN:[loss=0.091]\n","INFO:root:[240 epochs]: TRAIN:[loss=0.091]\n"," 50%|█████     | 251/500 [00:00<00:00, 618.55epoch/s]INFO:root:[260 epochs]: TRAIN:[loss=0.091]\n","INFO:root:[280 epochs]: TRAIN:[loss=0.091]\n","INFO:root:[300 epochs]: TRAIN:[loss=0.091]\n"," 63%|██████▎   | 314/500 [00:00<00:00, 621.79epoch/s]INFO:root:[320 epochs]: TRAIN:[loss=0.091]\n","INFO:root:[340 epochs]: TRAIN:[loss=0.091]\n","INFO:root:[360 epochs]: TRAIN:[loss=0.091]\n"," 75%|███████▌  | 377/500 [00:00<00:00, 617.21epoch/s]INFO:root:[380 epochs]: TRAIN:[loss=0.091]\n","INFO:root:[400 epochs]: TRAIN:[loss=0.091]\n","INFO:root:[420 epochs]: TRAIN:[loss=0.091]\n","INFO:root:[440 epochs]: TRAIN:[loss=0.091]\n"," 88%|████████▊ | 441/500 [00:00<00:00, 621.49epoch/s]INFO:root:[460 epochs]: TRAIN:[loss=0.091]\n","INFO:root:[480 epochs]: TRAIN:[loss=0.091]\n","100%|██████████| 500/500 [00:00<00:00, 621.82epoch/s]\n","INFO:root:Finished Training\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8518518518518519\n"]}],"source":["from snorkel.labeling.model import LabelModel\n","from sklearn.metrics import accuracy_score\n","\n","\n","label_matrix = multiannotator_labels.values\n","\n","label_model = LabelModel(cardinality=4, verbose=True)\n","\n","label_model.fit(L_train=label_matrix, \n","                n_epochs=500, \n","                seed=2024, \n","                log_freq=20, \n","                l2=0.1, \n","                lr=0.001, \n","                lr_scheduler=\"linear\", \n","                optimizer=\"adam\")\n","\n","predicted_labels = label_model.predict(L=label_matrix)\n","\n","accuracy = accuracy_score(Y_train, predicted_labels)\n","print(f\"Accuracy: {accuracy}\")"]},{"cell_type":"markdown","metadata":{"id":"nMc3k_PPJlgA"},"source":["**(b) Refining Labels with Cleanlab:** (10%)\n","\n","In this second trial, we'll leverage the `cleanlab` library to further analyze and refine the labels obtained from crowdsourcing. The process will involve deriving consensus labels from the crowdsourced data, using majority voting and model predictions.\n","\n","**Steps:**\n","\n","1. **Majority Vote Labels**:\n","   - Utilize the `get_majority_vote_label()` function to aggregate the labels from different workers for each sample into a single majority vote label.\n","   \n","2. **Model Predictions**:\n","   - Apply a 5-fold cross-validation on the training dataset labeled with the majority vote results. Use the model below to compute out-of-sample predicted probabilities for each sample.\n","   ```python\n","    LogisticRegression(solver='liblinear', penalty='l1', C=0.1, random_state=2024)\n","   ```\n","\n","3. **Consensus Labels**:\n","   - Employ the `get_label_quality_multiannotator()` function from `cleanlab` to combine the out-of-sample predicted probabilities with the crowdsourced labels. This function will help generate consensus labels, which aim to be more accurate by considering both worker disagreement and model confidence.\n","\n","4. **Evaluate Accuracy**:\n","   - Calculate the accuracy of both the majority vote labels and the consensus labels by comparing them against the ground truth labels in `labels.csv`. As with previous tasks, remember that the ground truth is strictly for evaluation purposes.\n","\n","**Hints:**\n","- Explore the Cleanlab documentation [here](https://github.com/cleanlab/cleanlab) for additional insights into functions like `get_majority_vote_label()` and `get_label_quality_multiannotator()`."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Majority Vote Accuracy: 0.8481481481481481\n","Consensus Label Accuracy: 0.6888888888888889\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from cleanlab.classification import CleanLearning\n","\n","\n","def get_majority_vote_labels(multiannotator_labels):\n","    from scipy import stats\n","    majority_vote_labels = stats.mode(multiannotator_labels, axis=1, nan_policy='omit').mode\n","    return majority_vote_labels.flatten()\n","\n","majority_vote_labels = get_majority_vote_labels(multiannotator_labels)\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X_train.values)\n","\n","valid_indices = ~np.isnan(majority_vote_labels)\n","X_filtered = X_scaled[valid_indices]\n","y_majority_vote_filtered = majority_vote_labels[valid_indices].astype(int)\n","\n","logreg = LogisticRegression(solver='liblinear', penalty='l1', C=0.1, random_state=2024)\n","\n","from sklearn.model_selection import cross_val_predict\n","predicted_probs = cross_val_predict(logreg, X_filtered, y_majority_vote_filtered, cv=5, method='predict_proba')\n","\n","clean_model = CleanLearning(clf=logreg)\n","\n","clean_model.fit(X_filtered, y_majority_vote_filtered)\n","consensus_labels = clean_model.predict(X_filtered)\n","\n","consensus_label_accuracy = accuracy_score(Y_train[:len(consensus_labels)], consensus_labels)\n","majority_vote_accuracy = accuracy_score(Y_train[:len(consensus_labels)], y_majority_vote_filtered)\n","\n","print(f\"Majority Vote Accuracy: {majority_vote_accuracy}\")\n","print(f\"Consensus Label Accuracy: {consensus_label_accuracy}\")\n"]},{"cell_type":"markdown","metadata":{"id":"R9Y2DByyKINF"},"source":["**(c) Evaluate Random Forest Classifiers:** (10%)\n","\n","Since we don't have these crowdsourcing labels for the test set or new incoming data points, we can't use the `LabelModel` or obtain consensus label at inference time. In order to run inference on new incoming data points, we need to train a discriminative model! Train a model using the following setup:\n","\n","```python\n","RandomForestClassifier(random_state=2024, n_estimators=10)\n","```\n","**Steps:**\n","- Train a classifier for each type of label.\n","    - **Snorkel Labels**: Generated in part (a).\n","    - **Majority-Vote Labels**: Obtained in part (b) from `get_majority_vote_label()`.\n","    - **Consensus Labels**: Derived in part (b) from `get_label_quality_multiannotator()`.\n","- Evaluate and report the classification accuracy on the test set.\n","- Determine which classifier performs best based on the accuracy scores."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"IF9TqRlRiEE5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Difference between Snorkel and Majority Vote labels: 25 samples differ.\n","Snorkel Labels Accuracy: 0.7666666666666667\n","Majority Vote Labels Accuracy: 0.7666666666666667\n","Consensus Labels Accuracy: 0.6\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","\n","snorkel_predicted_labels = label_model.predict(L=multiannotator_labels.values)\n","\n","def get_majority_vote_labels(multiannotator_labels):\n","    from scipy import stats\n","    majority_vote_labels = stats.mode(multiannotator_labels, axis=1, nan_policy='omit').mode\n","    return majority_vote_labels.flatten()\n","\n","majority_vote_labels = get_majority_vote_labels(multiannotator_labels)\n","\n","label_difference = np.sum(snorkel_predicted_labels != majority_vote_labels)\n","print(f\"Difference between Snorkel and Majority Vote labels: {label_difference} samples differ.\")\n","\n","def train_and_evaluate_random_forest(X_train, y_train, X_test, y_test):\n","    rf_model = RandomForestClassifier(random_state=2024, n_estimators=10)\n","    rf_model.fit(X_train, y_train)\n","    y_pred = rf_model.predict(X_test)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    return accuracy\n","\n","snorkel_accuracy = train_and_evaluate_random_forest(X_train, snorkel_predicted_labels, X_test, Y_test)\n","\n","majority_vote_accuracy = train_and_evaluate_random_forest(X_train, majority_vote_labels, X_test, Y_test)\n","\n","consensus_label_accuracy = train_and_evaluate_random_forest(X_train, consensus_labels, X_test, Y_test)\n","\n","# 打印準確度\n","print(f\"Snorkel Labels Accuracy: {snorkel_accuracy}\")\n","print(f\"Majority Vote Labels Accuracy: {majority_vote_accuracy}\")\n","print(f\"Consensus Labels Accuracy: {consensus_label_accuracy}\")\n"]},{"cell_type":"markdown","metadata":{"id":"_O8wzGV-Epe-"},"source":["> Ans: *double click here to answer the question.* <bd>\n","\n","Best:\n","Snokel and Majority vote \n","accuracy = 0.7667"]},{"cell_type":"markdown","metadata":{"id":"le9kFq4PMsLf"},"source":["**(d) Enhanced Random Forest Training:** (10%)\n","\n","Train two additional Random Forest classifiers with the specifications:\n","```python\n","RandomForestClassifier(random_state=2024, n_estimators=10)\n","```\n","\n","**Steps:**\n","- Fit each classifier using the respective sample weights for the labels.\n","    - **Snorkel Labels**: Use `inv_entropy()` to calculate weights based on prediction probabilities from the `Snorkel` `LabelModel`.\n","    - **Consensus Labels**: Use `consensus_quality_score` from `Cleanlab` for weights.\n","- Evaluate and report the classification accuracy on the test set.\n","- Compare the results to those from (c) to assess performance improvement.\n","\n","Hint: Refer to [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.fit) for the `sample_weight` paprameter."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"U2bN2t1pMvZ4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Snorkel Weighted Labels Accuracy: 0.8\n","Consensus Weighted Labels Accuracy: 0.6\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from scipy.stats import entropy  # 正確導入 entropy 函數\n","\n","X = pd.read_csv('data.csv', names=[0,1])\n","true_labels = np.loadtxt('labels.csv', delimiter=',')\n","multiannotator_labels = pd.read_csv('crowdsourcing.csv')\n","\n","X_train, X_test, multiannotator_labels, ano_unseen, Y_train, Y_test = train_test_split(\n","    X, multiannotator_labels, true_labels, test_size=0.1, random_state=2024\n",")\n","\n","snorkel_predicted_labels = label_model.predict(L=multiannotator_labels.values)\n","\n","def get_majority_vote_labels(multiannotator_labels):\n","    from scipy import stats\n","    majority_vote_labels = stats.mode(multiannotator_labels, axis=1, nan_policy='omit').mode\n","    return majority_vote_labels.flatten()\n","\n","majority_vote_labels = get_majority_vote_labels(multiannotator_labels)\n","\n","\n","def inv_entropy(probs):\n","    \"\"\"計算反向熵作為樣本權重\"\"\"\n","    return 1.0 / (entropy(probs, axis=1) + 1e-6)  # 避免除以0\n","\n","snorkel_probs = label_model.predict_proba(L=multiannotator_labels.values)\n","snorkel_weights = inv_entropy(snorkel_probs)\n","\n","def train_and_evaluate_random_forest_with_weights(X_train, y_train, X_test, y_test, sample_weights):\n","    rf_model = RandomForestClassifier(random_state=2024, n_estimators=10)\n","    rf_model.fit(X_train, y_train, sample_weight=sample_weights)\n","    y_pred = rf_model.predict(X_test)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    return accuracy\n","\n","snorkel_weighted_accuracy = train_and_evaluate_random_forest_with_weights(X_train, snorkel_predicted_labels, X_test, Y_test, snorkel_weights)\n","\n","consensus_probs = clean_model.predict_proba(X_train)\n","consensus_weights = inv_entropy(consensus_probs)\n","\n","consensus_weighted_accuracy = train_and_evaluate_random_forest_with_weights(X_train, consensus_labels, X_test, Y_test, consensus_weights)\n","\n","print(f\"Snorkel Weighted Labels Accuracy: {snorkel_weighted_accuracy}\")\n","print(f\"Consensus Weighted Labels Accuracy: {consensus_weighted_accuracy}\")\n"]},{"cell_type":"markdown","metadata":{"id":"KcyC4CAFEtom"},"source":["> Ans: *double click here to answer the question.*\n","\n","在Snornel中從76.67% 提升到 80% 說明應用樣本權重可以提升性能\n","\n","而Consensus中則是維持60%"]},{"cell_type":"markdown","metadata":{"id":"Qhbc-fs3mc4g"},"source":["## Q3: Analyze StackOverflow dataset using SQL"]},{"cell_type":"markdown","metadata":{"id":"FZWBn2fiCh0J"},"source":["Kaggle has a rich number of [BigQuery](https://www.kaggle.com/datasets?fileType=bigQuery) and [SQLite](https://www.kaggle.com/datasets?fileType=sqlite) datasets that you can practice your SQL skill.\n","\n","In this question, we are going to examine the StackOverflow dataset. [Stack Overflow](https://stackoverflow.com/) is a popular question and answer site for technical questions.\n","\n","Hint: It is recommended to answer this question in Kaggle, where you can access the dataset directly."]},{"cell_type":"markdown","metadata":{"id":"w9iXYvI7gHDx"},"source":["Firstly, if you are using colab, use the following code snippet to setup the client. For more detail, please refer to our lab."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"_ArDmIuhJpdM"},"outputs":[],"source":["from google.cloud import bigquery\n","from google.oauth2 import service_account\n","import sys\n","\n","# Upload JSON file here\n","from google.colab import files\n","uploaded = files.upload()\n","\n","path_of_json = 'nomadic-botany-435608-b6-e1a2d53f264a.json'  #@param {type: \"string\"}\n","\n","# TODO(developer): Set path_of_json to the path to the service account key file.\n","\n","credentials = service_account.Credentials.from_service_account_file(\n","    path_of_json\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_f_cHz6nH4I"},"outputs":[],"source":["if \"google.colab\" in sys.modules:\n","    client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n","else:\n","    # Below and create a \"Client\" object if you are using Kaggle\n","    client = bigquery.Client()"]},{"cell_type":"markdown","metadata":{"id":"9batOLKbJmLR"},"source":["**(a) Initial Exploration of the Stack Overflow Dataset:** (10%)\n","\n","Begin your analysis by familiarizing yourself with the structure and contents of the Stack Overflow dataset:\n","\n","1. **List All Tables**: Print the names of all tables available in the dataset.\n","2. **View Table Schemas**: Display the schema for the `posts_questions` and `posts_answers` tables.\n","3. **Preview Data**: Retrieve and preview the first ten rows from each of the tables mentioned above.\n","\n","**Hint:** Use the following code snippet to reference the dataset in your client setup:\n","```python\n","dataset_ref = client.dataset(\"stackoverflow\", project=\"bigquery-public-data\")\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lB3YsScAw28g"},"outputs":[],"source":["# coding your answer here.\n","from google.cloud import bigquery\n","\n","dataset_ref = client.dataset(\"stackoverflow\", project=\"bigquery-public-data\")\n","\n","dataset = client.get_dataset(dataset_ref)\n","tables = list(client.list_tables(dataset))\n","\n","print(\"Tables in dataset:\")\n","for table in tables:\n","    print(table.table_id)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["questions_table_ref = dataset_ref.table(\"posts_questions\")\n","questions_table = client.get_table(questions_table_ref)\n","\n","print(\"\\nSchema of posts_questions table:\")\n","for field in questions_table.schema:\n","    print(f\"{field.name}: {field.field_type}\")\n","\n","answers_table_ref = dataset_ref.table(\"posts_answers\")\n","answers_table = client.get_table(answers_table_ref)\n","\n","print(\"\\nSchema of posts_answers table:\")\n","for field in answers_table.schema:\n","    print(f\"{field.name}: {field.field_type}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["query_questions = \"\"\"\n","SELECT *\n","FROM `bigquery-public-data.stackoverflow.posts_questions`\n","LIMIT 10\n","\"\"\"\n","\n","questions_query_job = client.query(query_questions)\n","questions_results = questions_query_job.result()\n","\n","print(\"\\nFirst 10 rows from posts_questions table:\")\n","for row in questions_results:\n","    print(dict(row))"]},{"cell_type":"markdown","metadata":{"id":"qLJkoaPELjzq"},"source":["**(b) Daily Post Counts for 2020:** (10%)\n","\n","Write an SQL query to count the number of posts created each day in the `posts_questions` table for the year 2020:\n","\n","- **Filter by Year**: Use `WHERE` and `EXTRACT()` to select posts from 2020 only.\n","- **Date Column**: Format the `creation_date` in DATE format (e.g. 2021-01-01) and rename it to \"created_day\". (Remember the SELECT... from clause, DATE() function and `AS` command).\n","- **Count Posts**: Count the daily posts and label this column as \"number_of_posts\". (Remember the `COUNT()` function).\n","- **Group and Sort**: Group the results by \"created_day\" using `GROUP BY` and order them by \"created_day\" in ascending order using `ORDER BY`.\n","\n","Your query should return a dataframe with 366 rows and two columns, showing the date and corresponding post count.\n","\n","<center>\n","\n","| created_day | number_of_posts |\n","|:-----------:|:---------------:|\n","|  2020-01-01 |       2390      |\n","|  2020-01-02 |       4601      |\n","|  2020-01-03 |       4816      |\n","|     ...     |       ....   |\n","|  2020-12-31 |       3498      |\n","\n","</center>\n","\n","Generate a line plot with \"created_day\" on the x-axis and \"number_of_posts\" on the y-axis to visualize daily posting trends. What patterns do you observe from the line plot regarding post frequency throughout 2020?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Id0aY2dzr0OS"},"outputs":[],"source":["# coding your answer here.\n","query = \"\"\"\n","SELECT\n","  DATE(creation_date) AS created_day,\n","  COUNT(*) AS number_of_posts\n","FROM\n","  `bigquery-public-data.stackoverflow.posts_questions`\n","WHERE\n","  EXTRACT(YEAR FROM creation_date) = 2020\n","GROUP BY\n","  created_day\n","ORDER BY\n","  created_day ASC\n","     \"\"\"\n","\n","############   Do not modify the code below     ############\n","# Set up the query (cancel the query if it would use too much of\n","# your quota, with the limit set to 1 GB)\n","safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n","query_job = client.query(query, job_config=safe_config)\n","\n","# API request - run the query, and return a pandas DataFrame\n","results = query_job.to_dataframe()\n","############   Do not modify the code above     ############"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mF7oFgDutCaJ"},"outputs":[],"source":["# coding your answer here.\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(12, 6))\n","plt.plot(results['created_day'], results['number_of_posts'], marker='o')\n","plt.title('Daily Post Counts on Stack Overflow (2020)', fontsize=14)\n","plt.xlabel('Date', fontsize=12)\n","plt.ylabel('Number of Posts', fontsize=12)\n","plt.grid(True)\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"WkALZDiz2rkB"},"source":["> Ans: *double click here to answer the question.* <bd>\n","\n","反映發帖數量每天的波動很大, 可能是工作日和周末的影響, 還有某些日期突然增多也許是有特殊事件或技術討論重大發展. "]},{"cell_type":"markdown","metadata":{"id":"3d5qD12pL8nB"},"source":["**(c) Analyzing User Engagement with 'pandas' Tag**: (10%)\n","\n","`posts_questions` has a column called tags which lists the topics/technologies each question is about. `posts_answers` has a column called `parent_id` which identifies the ID of the question each answer corresponds to. You can then join two tables by the `parent_id` in `posts_answers` and the `id` in `posts_questions`. `posts_answers` also has an `owner_user_id` column which specifies the ID of the user who answered the question.\n","\n","Now, write a query that has a single row for each user who answered at least one question with a tag that equals to string `pandas`. Your results should have two columns (Remember the `SELET...WHERE` clause) and follow the below restrictions:\n","\n","* `owner_user_id` - contains the `owner_user_id` column from the `posts_answers` table (Remember the `INNER JOIN` clause)\n","* `number_of_answers` - contains the number of answers the user has written to `pandas` related questions using the `tage` column (Remember the `AS`, `GROUP BY` and `COUNT` clause)\n","* Discard the rows whose `number_of_answers` is smaller or equal to 3 (Remember the `HAVING` clause)\n","\n","<center>\n","\n","| owner_user_id | number_of_answers |\n","|---------------|-------------------|\n","| 1234567       | 794               |\n","| 2345678       | 304               |\n","|     ...     |       ....   |\n","|  9999999 |       4      |\n","\n","</center>\n","\n","In the retrieve data frame, which user answers most questions in the pandas domain? Try to find the email of the user.\n","\n","Hint: You can find the public user profile by appending the ID after https://stackoverflow.com/users/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NipS2aIIMC0i"},"outputs":[],"source":["# coding your answer here.\n","query = \"\"\"\n","    SELECT\n","        a.owner_user_id AS owner_user_id,\n","        COUNT(a.id) AS number_of_answers\n","    FROM\n","        `bigquery-public-data.stackoverflow.posts_answers` a\n","    INNER JOIN\n","        `bigquery-public-data.stackoverflow.posts_questions` q\n","    ON\n","        a.parent_id = q.id\n","    WHERE\n","        q.tags LIKE '%<pandas>%'\n","    GROUP BY\n","        owner_user_id\n","    HAVING\n","        COUNT(a.id) > 3\n","    ORDER BY\n","        number_of_answers DESC\n","\"\"\"\n","############   Do not modify the code below     ############\n","# Set up the query (cancel the query if it would use too much of\n","# your quota, with the limit set to 1 GB)\n","safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n","query_job = client.query(query, job_config=safe_config)\n","\n","# API request - run the query, and return a pandas DataFrame\n","results = query_job.to_dataframe()\n","############   Do not modify the code above     ############"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7xQDjw-Qy0_A"},"outputs":[],"source":["# coding your answer here.\n","\n","top_user = results.iloc[0]\n","top_user_id = top_user['owner_user_id']\n","print(f\"The user who answered the most 'pandas' questions has the ID: {top_user_id}\")"]},{"cell_type":"markdown","metadata":{"id":"N1PMRwwY2mNq"},"source":["> Ans: *double click here to answer the question.*\n","\n","https://stackoverflow.com/users/16343464/mozway"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":0}
